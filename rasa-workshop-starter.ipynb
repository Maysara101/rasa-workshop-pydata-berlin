{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building conversational AI with the Rasa stack\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "\n",
    "This notebook is a basis for my workshop at PyData 2018 Berlin. If you have any questions or would like to learn more about anything included in this notebook, please let me know or get in touch by juste@rasa.com.\n",
    "\n",
    "In this workshop we are going to build a chatbot capable of checking in on people's mood and take the necessary actions to cheer them up. \n",
    "\n",
    "\n",
    "The tutorial consists of three parts:\n",
    "\n",
    "\n",
    "*   Part 0: Installation and setup\n",
    "*   Part 1: Teaching the chatbot to understand user inputs using Rasa NLU model\n",
    "*   Part 2: Teaching the chatbot to handle multi-turn conversations using dialogue management model.\n",
    "*   Part 3: Resources and tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Installation\n",
    "\n",
    "### Let's start with jupyter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of Rasa\n",
    "Let's start with the installation of Rasa NLU, Rasa Core and a spacy language model. If you have already installed, you can skip this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasa_core\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/bc/b5c886bc0bf15785b404a369c98f2159968d1b563e6ac47ef3acb1e7509e/rasa_core-0.13.0-py3-none-any.whl (204kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 4.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rasa_nlu[spacy]\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/b7/e1211e256172284998fc0d86abb117e54110be54d646e3c7a3fadec6d0d0/rasa_nlu-0.14.1-py2.py3-none-any.whl\n",
      "Collecting rocketchat-API~=0.6.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/1b/86a5706a575493673ffacd20d094cb9f13a3e6f87f7f124e5cb9bd652886/rocketchat_API-0.6.25-py3-none-any.whl\n",
      "Collecting questionary>=1.0.1 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/5f/1f230d9fa90f8716fe4d38c293cc5614172c4a53629bffdf81f42ecb4494/questionary-1.0.2-py3-none-any.whl\n",
      "Collecting python-socketio~=3.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/f2/f61d999bdc90c3d0f9c81df029bbb80c227b02d4e794beb38296b12fcfb0/python_socketio-3.1.1-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 9.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fbmessenger~=5.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/8c/20be00d1e30bd3d905e2977ba0115822985d159196194e5dc58ddf127e07/fbmessenger-5.4.0-py2.py3-none-any.whl\n",
      "Collecting terminaltables~=3.1 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
      "Collecting slackclient~=1.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/2f/1378e64a843a5a8a83d73caa59ac88c36c67e2b41ac0fab3422080ff13bd/slackclient-1.3.0-py2.py3-none-any.whl\n",
      "Collecting colorclass~=2.2 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/37/ea/ae8dbb956939d4392e6a7fdef87fda273854da1128edae016c4104240be8/colorclass-2.2.0.tar.gz\n",
      "Collecting typing~=3.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: packaging~=18.0 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (18.0)\n",
      "Requirement already satisfied, skipping upgrade: requests~=2.20 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (2.20.1)\n",
      "Collecting pika~=0.12.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/48/72de47f63ba353bacd74b76bb65bc63620b0706d8b0471798087cd5a4916/pika-0.12.0-py2.py3-none-any.whl (108kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 7.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm~=4.0 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (4.28.1)\n",
      "Collecting pydot~=1.4 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil~=2.7 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (2.7.5)\n",
      "Collecting fakeredis~=0.10.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/bd/2756ddf350c4bb308e3255f9dcd6610f8b01344947bf74d5d166dc66b0a2/fakeredis-0.10.3-py2.py3-none-any.whl\n",
      "Collecting pymongo~=3.7 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n",
      "\u001b[K    100% |████████████████████████████████| 409kB 3.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting rasa-core-sdk~=0.12.1 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/22/31af18238cdfbf44acf1b28181a476ab3f01774b64dafdf0b32865d15c63/rasa_core_sdk-0.12.1-py2.py3-none-any.whl\n",
      "Collecting flask-cors~=3.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n",
      "Collecting gevent~=1.4 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 1.7MB/s eta 0:00:01    16% |█████▍                          | 911kB 6.4MB/s eta 0:00:01    21% |███████                         | 1.2MB 8.1MB/s eta 0:00:01    95% |██████████████████████████████▋ | 5.2MB 9.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting apscheduler~=3.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/97/3a/fa3213cc325091b7729616594611fff31d72c2d4d590418c3efdf7424ae2/APScheduler-3.5.3-py2.py3-none-any.whl\n",
      "Collecting mattermostwrapper~=2.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/70/203660597d12788e958dd691aa11c3c29caa075eadb2ce94d2eb53099d1b/mattermostwrapper-2.1-py2.py3-none-any.whl\n",
      "Collecting pytz~=2018.9 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 8.8MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting python-telegram-bot~=11.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/6c/47932a4041ee76650ad1f45a80e1422077e1e99c08a4d7a61cfbe5393d41/python_telegram_bot-11.1.0-py2.py3-none-any.whl (326kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: networkx~=2.2 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (2.2)\n",
      "Collecting scipy~=1.2 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.6MB 286kB/s ta 0:00:011 2% |▊                               | 614kB 6.1MB/s eta 0:00:05    5% |█▊                              | 1.4MB 15.5MB/s eta 0:00:02    13% |████▍                           | 3.7MB 4.6MB/s eta 0:00:05    16% |█████▍                          | 4.5MB 6.1MB/s eta 0:00:04    50% |████████████████                | 13.3MB 4.9MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting tensorflow~=1.12.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 83.1MB 73kB/s  eta 0:00:01-1 day, 23:59:525                     | 4.8MB 7.7MB/s eta 0:00:11    6% |██                              | 5.3MB 15.9MB/s eta 0:00:05    9% |███                             | 7.9MB 7.6MB/s eta 0:00:10    12% |████                            | 10.2MB 11.6MB/s eta 0:00:07    12% |████                            | 10.6MB 6.1MB/s eta 0:00:12    17% |█████▋                          | 14.6MB 9.4MB/s eta 0:00:08    17% |█████▊                          | 14.9MB 13.2MB/s eta 0:00:06    21% |███████                         | 18.0MB 5.1MB/s eta 0:00:13    27% |████████▋                       | 22.5MB 7.7MB/s eta 0:00:08    29% |█████████▍                      | 24.3MB 4.9MB/s eta 0:00:12    40% |████████████▉                   | 33.3MB 19.7MB/s eta 0:00:03    67% |█████████████████████▋          | 56.1MB 10.9MB/s eta 0:00:03    69% |██████████████████████▍         | 58.1MB 9.5MB/s eta 0:00:03    76% |████████████████████████▌       | 63.7MB 16.6MB/s eta 0:00:02    78% |█████████████████████████▏      | 65.4MB 7.8MB/s eta 0:00:03    80% |█████████████████████████▋      | 66.6MB 5.1MB/s eta 0:00:04    83% |██████████████████████████▋     | 69.0MB 10.3MB/s eta 0:00:02    84% |███████████████████████████     | 70.3MB 10.0MB/s eta 0:00:02    85% |███████████████████████████▍    | 71.1MB 6.7MB/s eta 0:00:02    86% |███████████████████████████▌    | 71.5MB 11.6MB/s eta 0:00:01    87% |███████████████████████████▉    | 72.4MB 7.2MB/s eta 0:00:02    87% |████████████████████████████    | 72.8MB 7.6MB/s eta 0:00:02    88% |████████████████████████████▏   | 73.2MB 8.9MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting flask~=1.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 11.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting webexteamssdk~=1.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c6/8e700b876e4cae92721569f579a36d8eee62e296c4813704e258a19f405c/webexteamssdk-1.1.1.tar.gz (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn~=0.20.0 in /opt/conda/lib/python3.6/site-packages (from rasa_core) (0.20.0)\n",
      "Collecting twilio~=6.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/80/a6c07e32cc8bef9d2190c284704de77ef0b8acda58e021cbb7b0d8843cb4/twilio-6.23.1-py2.py3-none-any.whl\n",
      "Collecting numpy~=1.16 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.3MB 1.9MB/s eta 0:00:01   13% |████▍                           | 2.3MB 15.8MB/s eta 0:00:01    45% |██████████████▋                 | 7.9MB 11.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ruamel.yaml~=0.15.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/c5/79c7c3933045891a2df4f81130dc43e421dfe344903cab1dc17eb417daf5/ruamel.yaml-0.15.87-cp36-cp36m-manylinux1_x86_64.whl (664kB)\n",
      "\u001b[K    98% |███████████████████████████████▋| 655kB 7.4MB/s eta 0:00:011    100% |████████████████████████████████| 665kB 7.6MB/s \n",
      "\u001b[?25hCollecting redis~=2.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting coloredlogs~=10.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/0f/7877fc42fff0b9d70b6442df62d53b3868d3a6ad1b876bdb54335b30ff23/coloredlogs-10.0-py2.py3-none-any.whl (47kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jsonschema~=2.6 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\n",
      "Collecting colorhash~=1.0 (from rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/e1/50dbc513aa74e99eca4c47f2a8206711f0bec436fdddd95eebaf7eaaa1aa/colorhash-1.0.2-py2.py3-none-any.whl\n",
      "Collecting jsonpickle~=1.0 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
      "Collecting flask-jwt-simple~=0.0.3 (from rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/5f/432fde78e3a7dda20576396ebf561770a83104dc4b74a1ee84e71574ec0a/Flask-JWT-Simple-0.0.3.tar.gz\n",
      "Collecting pykwalify~=1.7.0 (from rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/9f/612de8ca540bd24d604f544248c4c46e9db76f6ea5eb75fb4244da6ebbf0/pykwalify-1.7.0-py2.py3-none-any.whl (40kB)\n",
      "\u001b[K    100% |████████████████████████████████| 40kB 3.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib~=2.0 in /opt/conda/lib/python3.6/site-packages (from rasa_nlu[spacy]) (2.2.3)\n",
      "Collecting boto3~=1.5 (from rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/8a/730acf258088f2b0615e1bf6acaa63e336a97b6eeb41ce4c5b7e8b636476/boto3-1.9.86-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 15.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle~=0.6.1 (from rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/87/7b7ef3038b4783911e3fdecb5c566e3a817ce3e890e164fc174c088edb1e/cloudpickle-0.6.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six~=1.11 in /opt/conda/lib/python3.6/site-packages (from rasa_nlu[spacy]) (1.11.0)\n",
      "Collecting klein~=17.10 (from rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/6b/adc97a7bb3fb781fdd9e49177ad873c1479f87b9745271cbeda81cbb9cc8/klein-17.10.0-py2.py3-none-any.whl\n",
      "Collecting simplejson~=3.13 (from rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.6MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting future~=0.16.0 (from rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/2b/8d082ddfed935f3608cc61140df6dcbf0edea1bc3ab52fb6c29ae3e81e85/future-0.16.0.tar.gz (824kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 10.3MB/s ta 0:00:01 6% |██                              | 51kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn-crfsuite~=0.3.6; extra == \"spacy\" (from rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
      "Collecting spacy<=2.0.18,>2.0; extra == \"spacy\" (from rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/6e/a89da6b5c83f8811e46e3a9270c1aed90e9b9ee6c60faf52b7239e5d3d69/spacy-2.0.18-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.2MB 547kB/s eta 0:00:01  6% |██                              | 1.6MB 6.5MB/s eta 0:00:04    29% |█████████▌                      | 7.5MB 7.6MB/s eta 0:00:03    61% |███████████████████▊            | 15.5MB 7.3MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: prompt-toolkit~=2.0 in /opt/conda/lib/python3.6/site-packages (from questionary>=1.0.1->rasa_core) (2.0.7)\n",
      "Collecting python-engineio>=3.2.0 (from python-socketio~=3.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/ae/0d61fcc020186c3c1d213b2fb1ddedd21bab5c603fa62cbedb2d3df96109/python_engineio-3.3.0-py2.py3-none-any.whl (115kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 23.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting websocket-client<1.0a0,>=0.35 (from slackclient~=1.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 204kB 9.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging~=18.0->rasa_core) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (2018.11.29)\n",
      "Collecting ConfigArgParse~=0.13.0 (from rasa-core-sdk~=0.12.1->rasa_core)\n",
      "  Using cached https://files.pythonhosted.org/packages/77/61/ae928ce6ab85d4479ea198488cf5ffa371bd4ece2030c0ee85ff668deac5/ConfigArgParse-0.13.0.tar.gz\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\" (from gevent~=1.4->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=0.7 in /opt/conda/lib/python3.6/site-packages (from apscheduler~=3.0->rasa_core) (40.6.2)\n",
      "Collecting tzlocal>=1.2 (from apscheduler~=3.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/89/e3687d3ed99bc882793f82634e9824e62499fdfdc4b1ae39e211c5b05017/tzlocal-1.5.1.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: cryptography in /opt/conda/lib/python3.6/site-packages (from python-telegram-bot~=11.0->rasa_core) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx~=2.2->rasa_core) (4.3.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow~=1.12.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting grpcio>=1.8.6 (from tensorflow~=1.12.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/a3/489ce6a67047263e9b0da8784b2925c4f89b688a6e33073c5bb6c4c2867f/grpcio-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (10.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.6MB 1.9MB/s ta 0:00:011   13% |████▍                           | 1.5MB 8.9MB/s eta 0:00:02    27% |████████▋                       | 2.9MB 8.2MB/s eta 0:00:01    64% |████████████████████▊           | 6.9MB 7.6MB/s eta 0:00:01    69% |██████████████████████▏         | 7.3MB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (0.32.3)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow~=1.12.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 15.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow~=1.12.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow~=1.12.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.1.6 (from tensorflow~=1.12.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 14.5MB/s a 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.13.0,>=1.12.0 (from tensorflow~=1.12.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 4.4MB/s ta 0:00:011    10% |███▍                            | 317kB 11.5MB/s eta 0:00:01    27% |█████████                       | 849kB 10.4MB/s eta 0:00:01    62% |████████████████████            | 1.9MB 4.8MB/s eta 0:00:01    73% |███████████████████████▋        | 2.2MB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (3.6.1)\n",
      "Collecting astor>=0.6.0 (from tensorflow~=1.12.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting click>=5.1 (from flask~=1.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=0.24 (from flask~=1.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.14 (from flask~=1.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 6.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: Jinja2>=2.10 in /opt/conda/lib/python3.6/site-packages (from flask~=1.0->rasa_core) (2.10)\n",
      "Collecting requests-toolbelt (from webexteamssdk~=1.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/8a/d710f792d6f6ecc089c5e55b66e66c3f2f35516a1ede5a8f54c13350ffb0/requests_toolbelt-0.8.0-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 16.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pysocks; python_version >= \"3.0\" in /opt/conda/lib/python3.6/site-packages (from twilio~=6.0->rasa_core) (1.6.8)\n",
      "Collecting PyJWT>=1.4.2 (from twilio~=6.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Collecting humanfriendly>=4.7 (from coloredlogs~=10.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 9.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=3.11 in /opt/conda/lib/python3.6/site-packages (from pykwalify~=1.7.0->rasa_core) (3.13)\n",
      "Collecting docopt>=0.6.2 (from pykwalify~=1.7.0->rasa_core)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib~=2.0->rasa_nlu[spacy]) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib~=2.0->rasa_nlu[spacy]) (1.0.1)\n",
      "Collecting botocore<1.13.0,>=1.12.86 (from boto3~=1.5->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/af/fd9c0f1f0fdc03d3367a56f35093f8b1020ba1a97ead9fa580156895944b/botocore-1.12.86-py2.py3-none-any.whl (5.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.3MB 1.9MB/s ta 0:00:011   9% |███                             | 501kB 6.4MB/s eta 0:00:01    15% |████▉                           | 798kB 5.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3~=1.5->rasa_nlu[spacy])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3~=1.5->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting Twisted>=15.5 (from klein~=17.10->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/0e/a72d85a55761c2c3ff1cb968143a2fd5f360220779ed90e0fadf4106d4f2/Twisted-18.9.0.tar.bz2 (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 2.6MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting incremental (from klein~=17.10->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite~=0.3.6; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
      "\u001b[K    100% |████████████████████████████████| 757kB 7.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate (from sklearn-crfsuite~=0.3.6; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/61/9b0520c28eb199a4b1ca667d96dd625bba003c14c75230195f9691975f85/cymem-2.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/38/40/6b39438f7eefbb46460f645b8eefebc0c5f1cd38a934a2189c39d8bd0225/murmurhash-1.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting thinc<6.13.0,>=6.12.1 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/a7/46640a46fd707aeb204aa4257a70974b6a22a0204ba703164d803215776f/thinc-6.12.1-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.9MB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting regex==2018.01.10 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
      "\u001b[K    100% |████████████████████████████████| 614kB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac<1.0.0,>=0.9.6 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy]) (0.2.8.2)\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 5.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 6.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit~=2.0->questionary>=1.0.1->rasa_core) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography->python-telegram-bot~=11.0->rasa_core) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography->python-telegram-bot~=11.0->rasa_core) (1.11.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow~=1.12.0->rasa_core) (2.7.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow~=1.12.0->rasa_core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10->flask~=1.0->rasa_core) (1.1.0)\n",
      "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.86->boto3~=1.5->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 8.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zope.interface>=4.4.2 (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/17/1d198a6aaa9aa4590862fe3d3a2ed7dd808050cab4eebe8a2f2f813c1376/zope.interface-4.6.0-cp36-cp36m-manylinux1_x86_64.whl (167kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 5.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting constantly>=15.1 (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
      "Collecting Automat>=0.3.0 (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/86/14c16bb98a5a3542ed8fed5d74fb064a902de3bdd98d6584b34553353c45/Automat-0.7.0-py2.py3-none-any.whl\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/b6/84d0c863ff81e8e7de87cff3bd8fd8f1054c227ce09af1b679a8b17a9274/hyperlink-18.0.0-py2.py3-none-any.whl\n",
      "Collecting PyHamcrest>=1.9.0 (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d5/d37fd731b7d0e91afcc84577edeccf4638b4f9b82f5ffe2f8b62e2ddc609/PyHamcrest-1.9.0-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa_nlu[spacy]) (18.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy]) (0.9.0.1)\n",
      "Collecting wrapt<1.11.0,>=1.10.0 (from thinc<6.13.0,>=6.12.1->spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
      "Collecting msgpack-numpy<0.4.4 (from thinc<6.13.0,>=6.12.1->spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Collecting msgpack<0.6.0,>=0.5.6 (from thinc<6.13.0,>=6.12.1->spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 15.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography->python-telegram-bot~=11.0->rasa_core) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<=2.0.18,>2.0; extra == \"spacy\"->rasa_nlu[spacy]) (0.9.0)\n",
      "Building wheels for collected packages: terminaltables, colorclass, webexteamssdk, flask-jwt-simple, simplejson, future, ConfigArgParse, tzlocal, termcolor, gast, absl-py, docopt, Twisted, tabulate, regex, ujson, wrapt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for terminaltables ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
      "  Running setup.py bdist_wheel for colorclass ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/d1/86/9d/16127127306a92d7fd30267890a5634026c045391979c4c317\n",
      "  Running setup.py bdist_wheel for webexteamssdk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/98/09/8a/03b3fcfe0a351b960427e278d87191e9a3065cd2a36b84ab3d\n",
      "  Running setup.py bdist_wheel for flask-jwt-simple ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/5d/86/c2/49573c0ce194f3073438e56dad49c462fe9c9a69a4fbe7b3fc\n",
      "  Running setup.py bdist_wheel for simplejson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/bf/c9/a3/c538d90ef17cf7823fa51fc701a7a7a910a80f6a405bf15b1a\n",
      "  Running setup.py bdist_wheel for ConfigArgParse ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/76/11/eb/12113becd46c0e8a70b8a63f9405e46a1f61d4aaa8532d676b\n",
      "  Running setup.py bdist_wheel for tzlocal ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/15/ae/df/a67bf1ed84e9bf230187d36d8dcfd30072bea0236cb059ed91\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/90/db/f8/2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca\n",
      "  Running setup.py bdist_wheel for docopt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "  Running setup.py bdist_wheel for Twisted ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/57/2e/89/11ba83bc08ac30a5e3a6005f0310c78d231b96a270def88ca0\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
      "Successfully built terminaltables colorclass webexteamssdk flask-jwt-simple simplejson future ConfigArgParse tzlocal termcolor gast absl-py docopt Twisted tabulate regex ujson wrapt\n",
      "\u001b[31mrasa-nlu 0.14.1 has requirement coloredlogs~=9.0, but you'll have coloredlogs 10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrasa-nlu 0.14.1 has requirement packaging~=17.1, but you'll have packaging 18.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrasa-nlu 0.14.1 has requirement scikit-learn~=0.20.2, but you'll have scikit-learn 0.20.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: rocketchat-API, questionary, python-engineio, python-socketio, fbmessenger, terminaltables, websocket-client, slackclient, colorclass, typing, docutils, jmespath, botocore, s3transfer, boto3, cloudpickle, jsonschema, zope.interface, constantly, incremental, Automat, hyperlink, PyHamcrest, Twisted, Werkzeug, klein, greenlet, gevent, numpy, simplejson, humanfriendly, coloredlogs, future, ruamel.yaml, python-crfsuite, tabulate, sklearn-crfsuite, scipy, cymem, murmurhash, plac, wrapt, msgpack, msgpack-numpy, preshed, thinc, regex, ujson, spacy, rasa-nlu, pika, pydot, redis, fakeredis, pymongo, ConfigArgParse, click, itsdangerous, flask, flask-cors, rasa-core-sdk, pytz, tzlocal, apscheduler, mattermostwrapper, python-telegram-bot, termcolor, grpcio, keras-applications, keras-preprocessing, gast, absl-py, markdown, tensorboard, astor, tensorflow, requests-toolbelt, webexteamssdk, PyJWT, twilio, colorhash, jsonpickle, flask-jwt-simple, docopt, pykwalify, rasa-core\n",
      "  Found existing installation: cloudpickle 0.5.6\n",
      "    Uninstalling cloudpickle-0.5.6:\n",
      "      Successfully uninstalled cloudpickle-0.5.6\n",
      "  Found existing installation: jsonschema 3.0.0a3\n",
      "    Uninstalling jsonschema-3.0.0a3:\n",
      "      Successfully uninstalled jsonschema-3.0.0a3\n",
      "  Found existing installation: numpy 1.13.3\n",
      "    Uninstalling numpy-1.13.3:\n",
      "      Successfully uninstalled numpy-1.13.3\n",
      "  Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "  Found existing installation: pytz 2018.7\n",
      "    Uninstalling pytz-2018.7:\n",
      "      Successfully uninstalled pytz-2018.7\n",
      "Successfully installed Automat-0.7.0 ConfigArgParse-0.13.0 PyHamcrest-1.9.0 PyJWT-1.7.1 Twisted-18.9.0 Werkzeug-0.14.1 absl-py-0.7.0 apscheduler-3.5.3 astor-0.7.1 boto3-1.9.86 botocore-1.12.86 click-7.0 cloudpickle-0.6.1 colorclass-2.2.0 coloredlogs-10.0 colorhash-1.0.2 constantly-15.1.0 cymem-2.0.2 docopt-0.6.2 docutils-0.14 fakeredis-0.10.3 fbmessenger-5.4.0 flask-1.0.2 flask-cors-3.0.7 flask-jwt-simple-0.0.3 future-0.16.0 gast-0.2.2 gevent-1.4.0 greenlet-0.4.15 grpcio-1.18.0 humanfriendly-4.17 hyperlink-18.0.0 incremental-17.5.0 itsdangerous-1.1.0 jmespath-0.9.3 jsonpickle-1.1 jsonschema-2.6.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 klein-17.10.0 markdown-3.0.1 mattermostwrapper-2.1 msgpack-0.5.6 msgpack-numpy-0.4.3.2 murmurhash-1.0.1 numpy-1.16.0 pika-0.12.0 plac-0.9.6 preshed-2.0.1 pydot-1.4.1 pykwalify-1.7.0 pymongo-3.7.2 python-crfsuite-0.9.6 python-engineio-3.3.0 python-socketio-3.1.1 python-telegram-bot-11.1.0 pytz-2018.9 questionary-1.0.2 rasa-core-0.13.0 rasa-core-sdk-0.12.1 rasa-nlu-0.14.1 redis-2.10.6 regex-2018.1.10 requests-toolbelt-0.8.0 rocketchat-API-0.6.25 ruamel.yaml-0.15.87 s3transfer-0.1.13 scipy-1.2.0 simplejson-3.16.0 sklearn-crfsuite-0.3.6 slackclient-1.3.0 spacy-2.0.18 tabulate-0.8.3 tensorboard-1.12.2 tensorflow-1.12.0 termcolor-1.1.0 terminaltables-3.1.0 thinc-6.12.1 twilio-6.23.1 typing-3.6.6 tzlocal-1.5.1 ujson-1.35 webexteamssdk-1.1.1 websocket-client-0.54.0 wrapt-1.10.11 zope.interface-4.6.0\n",
      "Collecting en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz (120.8MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 120.9MB 26.1MB/s ta 0:00:01-1 day, 23:59:59                    | 133kB 331kB/s eta 0:06:05    4% |█▌                              | 5.5MB 8.1MB/s eta 0:00:15    4% |█▋                              | 5.9MB 6.2MB/s eta 0:00:19    5% |█▉                              | 6.7MB 13.9MB/s eta 0:00:09    6% |██                              | 7.7MB 1.6MB/s eta 0:01:09    6% |██                              | 7.9MB 10.5MB/s eta 0:00:11    6% |██▏                             | 8.1MB 2.4MB/s eta 0:00:48    7% |██▎                             | 8.7MB 6.0MB/s eta 0:00:19    7% |██▍                             | 9.0MB 1.6MB/s eta 0:01:11    7% |██▌                             | 9.4MB 4.0MB/s eta 0:00:29    7% |██▌                             | 9.6MB 582kB/s eta 0:03:12    9% |███                             | 11.1MB 7.8MB/s eta 0:00:15    10% |███▌                            | 13.1MB 3.3MB/s eta 0:00:33    11% |███▉                            | 14.4MB 4.0MB/s eta 0:00:27    19% |██████▍                         | 24.1MB 28.4MB/s eta 0:00:04    20% |██████▊                         | 25.3MB 3.3MB/s eta 0:00:29    23% |███████▌                        | 28.2MB 4.4MB/s eta 0:00:22    24% |███████▉                        | 29.5MB 1.3MB/s eta 0:01:11    24% |███████▉                        | 29.5MB 873kB/s eta 0:01:45    24% |████████                        | 30.2MB 25.2MB/s eta 0:00:04    25% |████████▎                       | 31.4MB 8.0MB/s eta 0:00:12    26% |████████▍                       | 31.6MB 3.6MB/s eta 0:00:25    27% |████████▊                       | 32.8MB 2.5MB/s eta 0:00:36    27% |████████▊                       | 32.9MB 1.4MB/s eta 0:01:02    27% |████████▊                       | 33.0MB 1.3MB/s eta 0:01:09    28% |█████████                       | 34.1MB 1.2MB/s eta 0:01:11    28% |█████████▎                      | 34.9MB 2.8MB/s eta 0:00:32    29% |█████████▎                      | 35.2MB 469kB/s eta 0:03:03    29% |█████████▍                      | 35.3MB 404kB/s eta 0:03:32    29% |█████████▋                      | 36.2MB 13.8MB/s eta 0:00:07�█▊                      | 36.6MB 13.0MB/s eta 0:00:07    30% |█████████▊                      | 36.9MB 5.3MB/s eta 0:00:16    31% |██████████                      | 37.7MB 13.5MB/s eta 0:00:07    32% |██████████▍                     | 39.1MB 18.7MB/s eta 0:00:05    34% |███████████                     | 41.8MB 11.0MB/s eta 0:00:08    35% |███████████▍                    | 43.1MB 2.1MB/s eta 0:00:38    40% |████████████▉                   | 48.5MB 3.9MB/s eta 0:00:19    41% |█████████████▏                  | 49.8MB 8.5MB/s eta 0:00:09    43% |██████████████                  | 53.1MB 14.0MB/s eta 0:00:05    49% |███████████████▊                | 59.6MB 7.8MB/s eta 0:00:08    56% |██████████████████              | 67.9MB 10.5MB/s eta 0:00:06    58% |██████████████████▋             | 70.1MB 8.7MB/s eta 0:00:06    59% |███████████████████             | 71.5MB 3.5MB/s eta 0:00:14    60% |███████████████████▎            | 72.8MB 7.6MB/s eta 0:00:07    63% |████████████████████▍           | 76.8MB 11.2MB/s eta 0:00:04    66% |█████████████████████▎          | 80.5MB 3.7MB/s eta 0:00:11    69% |██████████████████████▏         | 83.6MB 15.4MB/s eta 0:00:03    70% |██████████████████████▍         | 84.6MB 8.4MB/s eta 0:00:05    70% |██████████████████████▌         | 85.0MB 12.4MB/s eta 0:00:03    77% |█████████████████████████       | 94.0MB 8.1MB/s eta 0:00:04    80% |█████████████████████████▊      | 96.9MB 4.4MB/s eta 0:00:06    98% |███████████████████████████████▋| 119.5MB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "  Running setup.py install for en-core-web-md ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-md-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/en_core_web_md -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/en_core_web_md -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core rasa_nlu[spacy];\n",
    "\n",
    "# as well as install a language model:\n",
    "!{python} -m spacy download en_core_web_md\n",
    "!{python} -m spacy link en_core_web_md en --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the installation - we should have rasa_nlu: 0.12.3 and rasa_core: 0.9.6 installed, and spacy model should be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasa_nlu: 0.14.1 rasa_core: 0.13.0\n",
      "Loading spaCy language model...\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))\n",
    "print(\"Loading spaCy language model...\")\n",
    "print(spacy.load(\"en\")(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional Tools needed\n",
    "To do some of the visualizations you will also need graphviz. If you don't have graphviz installed, and this doesn't work: don't worry. I'll show you the graph and besides that visualization everything else will work.\n",
    "\n",
    "Try installing with anyone of these (or adapt to your operating system):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jovyan: \n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "#!brew install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and another python package and we are ready to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygraphviz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/b1/d6d849ddaf6f11036f9980d433f383d4c13d1ebcfc3cd09bc845bda7e433/pygraphviz-1.5.zip (117kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
      "  Running setup.py bdist_wheel for pygraphviz ... \u001b[?25lerror\n",
      "  Complete output from command /opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mv067g0g/pygraphviz/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-sa6p4kdf --python-tag cp36:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/agraph.py -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/release.py -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/version.py -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/__init__.py -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/graphviz.py -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  creating build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_subgraph.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_html.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_layout.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_graph.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_node_attributes.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_string.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_unicode.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_edge_attributes.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_readwrite.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_attributes.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/__init__.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_attribute_defaults.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_clear.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_drawing.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  copying pygraphviz/tests/test_setup.py -> build/lib.linux-x86_64-3.6/pygraphviz/tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info/PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info/dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info/top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.html' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc/build'\n",
      "  writing manifest file 'pygraphviz.egg-info/SOURCES.txt'\n",
      "  copying pygraphviz/graphviz.i -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  copying pygraphviz/graphviz_wrap.c -> build/lib.linux-x86_64-3.6/pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  creating build/temp.linux-x86_64-3.6\n",
      "  creating build/temp.linux-x86_64-3.6/pygraphviz\n",
      "  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -m64 -fPIC -m64 -fPIC -fPIC -I/opt/conda/include/python3.6m -c pygraphviz/graphviz_wrap.c -o build/temp.linux-x86_64-3.6/pygraphviz/graphviz_wrap.o\n",
      "  pygraphviz/graphviz_wrap.c:2987:10: fatal error: graphviz/cgraph.h: No such file or directory\n",
      "   #include \"graphviz/cgraph.h\"\n",
      "            ^~~~~~~~~~~~~~~~~~~\n",
      "  compilation terminated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for pygraphviz\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pygraphviz\n",
      "Failed to build pygraphviz\n",
      "Installing collected packages: pygraphviz\n",
      "  Running setup.py install for pygraphviz ... \u001b[?25lerror\n",
      "    Complete output from command /opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mv067g0g/pygraphviz/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-64roaatp/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    Trying dpkg\n",
      "    Trying pkg-config\n",
      "    Failed to find pkg-config\n",
      "    Trying dotneato-config\n",
      "    Failed to find dotneato-config\n",
      "    Failed to find dotneato-config\n",
      "    \n",
      "    Your Graphviz installation could not be found.\n",
      "    \n",
      "            1) You don't have Graphviz installed:\n",
      "               Install Graphviz (http://graphviz.org)\n",
      "    \n",
      "            2) Your Graphviz package might incomplete.\n",
      "               Install the binary development subpackage (e.g. libgraphviz-dev or similar.)\n",
      "    \n",
      "            3) You are using Windows\n",
      "               There are no PyGraphviz binary packages for Windows but you might be\n",
      "               able to build it from this source.  See\n",
      "               http://networkx.lanl.gov/pygraphviz/reference/faq.html\n",
      "    \n",
      "            If you think your installation is correct you will need to manually\n",
      "            provide path to graphviz include and library. For example:\n",
      "    \n",
      "            pip install pygraphviz --install-option=\"--include-path=/usr/include/graphviz\" --install-option=\"--library-path=/usr/lib/graphviz/\"\n",
      "    \n",
      "            The current setting of library_dirs and include_dirs is:\n",
      "    library_dirs=None\n",
      "    include_dirs=None\n",
      "    \n",
      "    error: Error locating graphviz.\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mv067g0g/pygraphviz/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-64roaatp/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-mv067g0g/pygraphviz/\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Natural Language Understanding\n",
    "\n",
    "At first, let's teach our chatbot how to understand user inputs. To do that, we are going to build a Rasa NLU model. Here is some data to get started: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversation_1:**   \n",
    "U: Hello  \n",
    "B: Hello, how are you doing?  \n",
    "U: I am doing great!  \n",
    "B: Great. Carry on!  \n",
    "    \n",
    "**Conversation_2:**  \n",
    "U: Hey  \n",
    "B: Hello, how are you doing?  \n",
    "U: I am very sad  \n",
    "B: To cheer you up, I can show you a cute picture of a cat, a dog or a bird. Choose one :)  \n",
    "U: A kitten  \n",
    "B: Here is something to cheer you up. Did that help?  \n",
    "U: Yes  \n",
    "B: Goodbye  \n",
    "  \n",
    "**Conversation_3:**    \n",
    "U: Heya  \n",
    "B: Hello, how are you doing?  \n",
    "U: Not so good and the only thing that could help me feel better is a picture of a puppy  \n",
    "B: Here is something to cheer you up. Did that help?  \n",
    "U: No  \n",
    "B: Goodbye  \n",
    "U: Bye  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training data for language understanding model\n",
    "\n",
    "\n",
    "Lets create some training data here, grouping user messages by their `intents`. The intent describes what the messages *mean*. Another important part of training data are `entities` - pieces of information which help a chatbot understand what specifically a user is asking about. Entities are labeled using the markdown link syntex: `[entity value](entity_type)` [More information about the data format](https://nlu.rasa.com/dataformat.html#markdown-format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training data is ready, we can define our NLU model. We can do that by constructing the processing pipeline which defines how structured data is extracted from unstructured user inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"sentiment.MyComponentA\"\n",
    "- name: \"sentiment.MyComponentB\"\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Rasa NLU Model\n",
    "\n",
    "We're going to train a model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a `\"greet\"` intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 5 (2 distinct intents)\n",
      "\t- Found intents: 'goodbye', 'greet'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "> /home/jovyan/work/sentiment.py(46)__init__()\n",
      "-> super().__init__(component_config)\n",
      "(Pdb) c\n",
      "> /home/jovyan/work/sentiment.py(138)__init__()\n",
      "-> super().__init__(component_config)\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.model:Starting to train component CompA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "> /home/jovyan/work/sentiment.py(62)train()\n",
      "-> pass\n",
      "(Pdb) training_data\n",
      "<rasa_nlu.training_data.training_data.TrainingData object at 0x7efe553d9cc0>\n",
      "(Pdb) cfg\n",
      "<rasa_nlu.config.RasaNLUModelConfig object at 0x7efe09ca9128>\n",
      "(Pdb) kwargs\n",
      "{}\n",
      "(Pdb) dir(training_data)\n",
      "['MIN_EXAMPLES_PER_ENTITY', 'MIN_EXAMPLES_PER_INTENT', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_lazy_entities', '_lazy_entity_examples', '_lazy_examples_per_entity', '_lazy_examples_per_intent', '_lazy_intent_examples', '_lazy_intents', 'as_json', 'as_markdown', 'entities', 'entity_examples', 'entity_synonyms', 'examples_per_entity', 'examples_per_intent', 'intent_examples', 'intents', 'lookup_tables', 'merge', 'persist', 'print_stats', 'regex_features', 'sanitize_examples', 'sort_regex_features', 'sorted_entities', 'sorted_intent_examples', 'train_test_split', 'training_examples', 'validate']\n",
      "(Pdb) training_data.entities\n",
      "set()\n",
      "(Pdb) training_data.intents\n",
      "{'goodbye', 'greet'}\n",
      "(Pdb) training_data.as_json()\n",
      "'{\\n  \"rasa_nlu_data\": {\\n    \"common_examples\": [\\n      {\\n        \"intent\": \"greet\",\\n        \"text\": \"hey\"\\n      },\\n      {\\n        \"intent\": \"greet\",\\n        \"text\": \"hello there\"\\n      },\\n      {\\n        \"intent\": \"goodbye\",\\n        \"text\": \"cu\"\\n      },\\n      {\\n        \"intent\": \"goodbye\",\\n        \"text\": \"good by\"\\n      },\\n      {\\n        \"intent\": \"goodbye\",\\n        \"text\": \"cee you later\"\\n      }\\n    ],\\n    \"regex_features\": [],\\n    \"lookup_tables\": [],\\n    \"entity_synonyms\": []\\n  }\\n}'\n",
      "(Pdb) training_data.lookup_tables\n",
      "[]\n",
      "(Pdb) training_data.entities\n",
      "set()\n",
      "(Pdb) cfg\n",
      "<rasa_nlu.config.RasaNLUModelConfig object at 0x7efe09ca9128>\n",
      "(Pdb) cfg()\n",
      "*** TypeError: 'RasaNLUModelConfig' object is not callable\n",
      "(Pdb) dir(cfg)\n",
      "['DEFAULT_PROJECT_NAME', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'as_dict', 'component_names', 'data', 'for_component', 'get', 'items', 'language', 'override', 'pipeline', 'set_component_attr', 'view']\n",
      "(Pdb) from pprint import pprint\n",
      "(Pdb) for i in dir(training_data):\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "(Pdb) for i in dir(training_data): pprint(i)\n",
      "'MIN_EXAMPLES_PER_ENTITY'\n",
      "'MIN_EXAMPLES_PER_INTENT'\n",
      "'__class__'\n",
      "'__delattr__'\n",
      "'__dict__'\n",
      "'__dir__'\n",
      "'__doc__'\n",
      "'__eq__'\n",
      "'__format__'\n",
      "'__ge__'\n",
      "'__getattribute__'\n",
      "'__gt__'\n",
      "'__hash__'\n",
      "'__init__'\n",
      "'__init_subclass__'\n",
      "'__le__'\n",
      "'__lt__'\n",
      "'__module__'\n",
      "'__ne__'\n",
      "'__new__'\n",
      "'__reduce__'\n",
      "'__reduce_ex__'\n",
      "'__repr__'\n",
      "'__setattr__'\n",
      "'__sizeof__'\n",
      "'__slotnames__'\n",
      "'__str__'\n",
      "'__subclasshook__'\n",
      "'__weakref__'\n",
      "'_lazy_entities'\n",
      "'_lazy_entity_examples'\n",
      "'_lazy_examples_per_entity'\n",
      "'_lazy_examples_per_intent'\n",
      "'_lazy_intent_examples'\n",
      "'_lazy_intents'\n",
      "'as_json'\n",
      "'as_markdown'\n",
      "'entities'\n",
      "'entity_examples'\n",
      "'entity_synonyms'\n",
      "'examples_per_entity'\n",
      "'examples_per_intent'\n",
      "'intent_examples'\n",
      "'intents'\n",
      "'lookup_tables'\n",
      "'merge'\n",
      "'persist'\n",
      "'print_stats'\n",
      "'regex_features'\n",
      "'sanitize_examples'\n",
      "'sort_regex_features'\n",
      "'sorted_entities'\n",
      "'sorted_intent_examples'\n",
      "'train_test_split'\n",
      "'training_examples'\n",
      "'validate'\n",
      "(Pdb) training_data.training_examples\n",
      "[<rasa_nlu.training_data.message.Message object at 0x7efe073e5a58>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5ac8>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5be0>, <rasa_nlu.training_data.message.Message object at 0x7efe073e56d8>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5cc0>]\n",
      "(Pdb) for i in training_data.training_examples: pprint(i)\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e5a58>\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e5ac8>\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e5be0>\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e56d8>\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e5cc0>\n",
      "(Pdb) training_data.training_examples[0]\n",
      "<rasa_nlu.training_data.message.Message object at 0x7efe073e5a58>\n",
      "(Pdb) aa = training_data.training_examples[0]\n",
      "(Pdb) dir(aa)\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'as_dict', 'build', 'data', 'get', 'output_properties', 'set', 'text', 'time']\n",
      "(Pdb) aa.text\n",
      "'hey'\n",
      "(Pdb) training_data.training_examples[0].text\n",
      "'hey'\n",
      "(Pdb) training_data.training_examples[0].data\n",
      "{'intent': 'greet'}\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component CompB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/jovyan/work/sentiment.py(153)train()\n",
      "-> with the training data. The component can rely on\n",
      "(Pdb) list\n",
      "148  \t\n",
      "149  \t    def train(self, training_data, cfg, **kwargs):\n",
      "150  \t        \"\"\"Train this component.\n",
      "151  \t\n",
      "152  \t        This is the components chance to train itself provided\n",
      "153  ->\t        with the training data. The component can rely on\n",
      "154  \t        any context attribute to be present, that gets created\n",
      "155  \t        by a call to :meth:`components.Component.pipeline_init`\n",
      "156  \t        of ANY component and\n",
      "157  \t        on any context attributes created by a call to\n",
      "158  \t        :meth:`components.Component.train`\n",
      "(Pdb) traing_data\n",
      "*** NameError: name 'traing_data' is not defined\n",
      "(Pdb) training_data\n",
      "<rasa_nlu.training_data.training_data.TrainingData object at 0x7efe553d9cc0>\n",
      "(Pdb) training_data.training_example[0].text\n",
      "*** AttributeError: 'TrainingData' object has no attribute 'training_example'\n",
      "(Pdb) traing_data\n",
      "*** NameError: name 'traing_data' is not defined\n",
      "(Pdb) training_data\n",
      "<rasa_nlu.training_data.training_data.TrainingData object at 0x7efe553d9cc0>\n",
      "(Pdb) training_data.training_examples\n",
      "[<rasa_nlu.training_data.message.Message object at 0x7efe073e5a58>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5ac8>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5be0>, <rasa_nlu.training_data.message.Message object at 0x7efe073e56d8>, <rasa_nlu.training_data.message.Message object at 0x7efe073e5cc0>]\n",
      "(Pdb) training_data.training_examples[0].text\n",
      "'hey'\n",
      "(Pdb) training_data.training_examples[0].data\n",
      "{'intent': 'greet'}\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.model:Finished training component.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "> /home/jovyan/work/sentiment.py(85)persist()\n",
      "-> import pdb;\n",
      "(Pdb) list\n",
      " 80  \t        of ANY component and\n",
      " 81  \t        on any context attributes created by a call to\n",
      " 82  \t        :meth:`components.Component.process`\n",
      " 83  \t        of components previous to this one.\"\"\"\n",
      " 84  \t        print('A')\n",
      " 85  ->\t        import pdb;\n",
      " 86  \t        pdb.set_trace()\n",
      " 87  \t        pass\n",
      " 88  \t\n",
      " 89  \t    def persist(self, model_dir):\n",
      " 90  \t        \"\"\"Persist this component to disk for future loading.\"\"\"\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using & evaluating the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model is performing on some of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(interpreter.parse(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating it by hand, the model can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Handling the dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taught our chatbot how to understand user inputs. Now, it's time to teach our chatbot how to make responses by training a dialogue management model using Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Stories\n",
    "\n",
    "The training data for dialogue management models is called `stories`. A story is an actual conversation where user inputs are expressed as intents as well as corresponding entities, and chatbot responses are expressed as actions.\n",
    "\n",
    "\n",
    "Let's take a look into the format of the stories in more detail:\n",
    "\n",
    "A story starts with `##` and you can give it a name. \n",
    "Lines that start with `*` are messages sent by the user. Although you don't write the *actual* message, but rather the intent (and the entities) that represent what the user *means*. \n",
    "Lines that start with `-` are *actions* taken by your bot. In this case all of our actions are just messages sent back to the user, like `utter_greet`, but in general an action can do anything, including calling an API and interacting with the outside world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Domain\n",
    "\n",
    "The domain specifies the universe that the bot operates in. In chatbot's world this universe consists of intents and entities as well as the actions which appear in training stories. The domain can also contain the templates for the answers a chabot should use to respond to the user and slots which will help the chatbot to keep track of the context. Let's look into the domain of our bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- mood_affirm\n",
    "- mood_deny\n",
    "- mood_great\n",
    "- mood_unhappy\n",
    "- inform\n",
    "\n",
    "    \n",
    "entities:\n",
    "- group\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_did_that_help\n",
    "- utter_happy\n",
    "- utter_goodbye\n",
    "- utter_unclear\n",
    "- utter_ask_picture\n",
    "\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! How are you?\"\n",
    "\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "\n",
    "  utter_unclear:\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  \n",
    "  utter_happy:\n",
    "  - text: \"Great carry on!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "  \n",
    "  utter_ask_picture:\n",
    "  - text: \"To cheer you up, I can show you a cute picture of a dog, a cat or a bird. Which one do you choose?\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses of the chatbot can be more than just simple text responses - we can call an API to retrieve some data which can later be used to create a response to user input. Let's create a custom action for our bot which, when predicted, will make an API and retrieve a picture of a dog, a cat or a bird, depending on which was specified by the user. The bot will know which type of picture should be received by retrieving the value of the slot `group`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.actions import Action\n",
    "from rasa_core.events import SlotSet\n",
    "from IPython.display import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_retrieve_image\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        \n",
    "\n",
    "        group = \n",
    "        r = \n",
    "        \n",
    "        response = r.content.decode()\n",
    "        response = response.replace('[\"',\"\")\n",
    "        response = response.replace('\"]',\"\")\n",
    "        \n",
    "        dispatcher.utter_message(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pro Tip: Visualising the Training Data\n",
    "\n",
    "You can visualise the stories to get a sense of how the conversations go. This is usually a good way to see if there are any stories which don't make sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.html\", max_history=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your Dialogue Model\n",
    "\n",
    "Now we are good to train the dialogue management model. We can specify what policies should be used to train it - in this case, the model is a neural network implemented in Keras which learns to predict which action to take next. We can also tweak the parameters of what percentage of training examples should be used for validation and how many epochs should be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting up the bot (with NLU)\n",
    "\n",
    "Now it's time for the fun part - starting the agent and chatting with it. We are going to start the `Agent` by loading our just trained dialogue model and using the previously trained nlu model as an interpreter for incoming user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.agent import Agent\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talking to the Bot (with NLU)\n",
    "\n",
    "Let's have a chat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the dialogue model\n",
    "As with the NLU model, instead of just subjectively testing the model, we can also evaluate the model on a dataset. You'll be using the training data set again, but usually you'd use a test data set separate from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.evaluate import run_story_evaluation\n",
    "\n",
    "run_story_evaluation(\"stories.md\", \"models/dialogue\", \n",
    "                     nlu_model_path=None, \n",
    "                     max_stories=None, \n",
    "                     out_file_plot=\"story_eval.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive learning\n",
    "Unfortunately, this doesn't work in Jupyter yet. Hence, we going to do this on the command line. To start the interactive training session open your command line and run `train_online.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources and tips\n",
    "\n",
    "- Rasa NLU [documentation](https://nlu.rasa.com/)\n",
    "- Rasa Core [documentation](https://core.rasa.com/)\n",
    "- Rasa Community on [Gitter](https://gitter.im/RasaHQ/home)\n",
    "- Rasa [Blog](https://blog.rasa.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
